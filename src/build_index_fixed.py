import os
from text_pipeline import preprocess, get_embedding as get_text_emb
from image_pipeline import get_image_embedding
from faiss_pipeline import FaissMultiModalSearch

print("ğŸš€ Building indexes for AI Challenge HCM...")

# Build index cho text
print("ğŸ“ Building text index...")
texts = []
metas = []

# Tá»± Ä‘á»™ng scan táº¥t cáº£ text files trong data/text/
text_dir = "data/text"
if os.path.exists(text_dir):
    text_files = [f for f in os.listdir(text_dir) if f.lower().endswith('.txt')]
    
    if not text_files:
        print("âš ï¸ No text files found in data/text/")
    else:
        print(f"ğŸ“ Found {len(text_files)} text files: {text_files}")
        
        for fname in text_files:
            fpath = os.path.join(text_dir, fname)
            print(f"ğŸ“– Processing file: {fname}")
            
            with open(fpath, encoding="utf-8") as f:
                for i, line in enumerate(f):
                    text = line.strip()
                    if text:
                        texts.append(text)
                        metas.append({"file": fname, "line": i+1, "text": text})
else:
    print("âš ï¸ Text directory data/text/ not found")

# Xá»­ lÃ½ text sau khi Ä‘Ã£ load táº¥t cáº£ files
if texts:
    print(f"ğŸ“Š Processing {len(texts)} text entries...")
    embs = [get_text_emb(preprocess(t)) for t in texts]
    # Sá»­ dá»¥ng FlatL2 cho dá»¯ liá»‡u nhá», IVF+PQ cho dá»¯ liá»‡u lá»›n
    use_ivfpq = len(embs) >= 256  # Chá»‰ dÃ¹ng IVF+PQ khi cÃ³ >= 256 samples
    nlist = min(16, len(embs) // 2) if len(embs) > 1 else 1
    
    text_searcher = FaissMultiModalSearch(dim=768, index_path="data/faiss_text.bin", meta_path="data/faiss_text.pkl", nlist=nlist, use_ivfpq=use_ivfpq)
    if use_ivfpq:
        text_searcher.train(embs)
    text_searcher.add_batch(embs, metas)
    text_searcher.save()
    print(f"âœ… Text index built successfully. Samples: {len(embs)}, nlist: {nlist}, use_ivfpq: {use_ivfpq}")
else:
    print("âš ï¸ No text files found in data/text/")

# Build index cho video (nhiá»u frames)
print("ğŸ–¼ï¸ Building image index from video frames...")
try:
    import cv2
    vid_dir = "data/vid"
    vid_embs = []
    vid_metas = []
    
    if os.path.exists(vid_dir):
        video_files = [f for f in os.listdir(vid_dir) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]
        
        if not video_files:
            print("âš ï¸ No video files found in data/vid/")
        else:
            for fname in video_files:
                vid_path = os.path.join(vid_dir, fname)
                vidcap = cv2.VideoCapture(vid_path)
                
                if not vidcap.isOpened():
                    print(f"âŒ Cannot open video: {fname}")
                    continue
                
                # Láº¥y thÃ´ng tin video
                total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = vidcap.get(cv2.CAP_PROP_FPS)
                duration = total_frames / fps if fps > 0 else 0
                
                print(f"ğŸ“¹ Processing video: {fname} ({total_frames} frames, {duration:.1f}s)")
                
                # Extract nhiá»u frames (má»—i 2 giÃ¢y 1 frame)
                frame_interval = max(1, int(fps * 2))  # 1 frame má»—i 2 giÃ¢y
                frame_count = 0
                
                for frame_idx in range(0, total_frames, frame_interval):
                    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                    success, image = vidcap.read()
                    
                    if success:
                        # LÆ°u frame táº¡m thá»i
                        frame_path = os.path.join(vid_dir, f"{fname}_frame_{frame_count}.jpg")
                        cv2.imwrite(frame_path, image)
                        
                        # Táº¡o embedding
                        emb = get_image_embedding(frame_path)
                        vid_embs.append(emb)
                        
                        # Metadata vá»›i thÃ´ng tin frame
                        time_sec = frame_idx / fps if fps > 0 else 0
                        vid_metas.append({
                            "file": fname, 
                            "frame": frame_count,
                            "time": f"{time_sec:.1f}s",
                            "description": f"Frame {frame_count} táº¡i {time_sec:.1f}s cá»§a video {fname}"
                        })
                        
                        # Cleanup
                        os.remove(frame_path)
                        frame_count += 1
                        
                        # Giá»›i háº¡n tá»‘i Ä‘a 10 frames per video
                        if frame_count >= 10:
                            break
                
                vidcap.release()
                print(f"âœ… Extracted {frame_count} frames from {fname}")
        
        if vid_embs:
            # Sá»­ dá»¥ng FlatL2 cho dá»¯ liá»‡u nhá» thay vÃ¬ IVF+PQ
            use_ivfpq = len(vid_embs) >= 256  # Chá»‰ dÃ¹ng IVF+PQ khi cÃ³ >= 256 samples
            nlist = min(4, len(vid_embs) // 2) if len(vid_embs) > 1 else 1
            
            image_searcher = FaissMultiModalSearch(dim=512, index_path="data/faiss_image.bin", meta_path="data/faiss_image.pkl", nlist=nlist, use_ivfpq=use_ivfpq)
            if use_ivfpq:
                image_searcher.train(vid_embs)
            image_searcher.add_batch(vid_embs, vid_metas)
            image_searcher.save()
            print(f"âœ… Image index built successfully. Samples: {len(vid_embs)}, nlist: {nlist}, use_ivfpq: {use_ivfpq}")
        else:
            print("âš ï¸ No video frames extracted")
    else:
        print("âš ï¸ Video directory data/vid/ not found")
        
except ImportError:
    print("âŒ Missing opencv-python. Install with: pip install opencv-python")
except Exception as e:
    print(f"âŒ Error processing videos: {e}")

# Build index cho áº£nh (náº¿u cÃ³ data/images/)
print("ğŸ–¼ï¸ Building image index from static images...")
img_dir = "data/images"
if os.path.exists(img_dir):
    img_embs = []
    img_metas = []
    image_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
    
    if not image_files:
        print("âš ï¸ No image files found in data/images/")
    else:
        for fname in image_files:
            fpath = os.path.join(img_dir, fname)
            emb = get_image_embedding(fpath)
            img_embs.append(emb)
            img_metas.append({"file": fname, "description": f"áº¢nh {fname}"})
            print(f"ğŸ–¼ï¸ Processed image: {fname}")
        
        if img_embs:
            nlist = min(8, len(img_embs) // 2) if len(img_embs) > 1 else 1
            use_ivfpq = len(img_embs) >= 256  # Chá»‰ dÃ¹ng IVF+PQ khi cÃ³ >= 256 samples
            image_searcher = FaissMultiModalSearch(dim=512, index_path="data/faiss_image_img.bin", meta_path="data/faiss_image_img.pkl", nlist=nlist, use_ivfpq=use_ivfpq)
            if use_ivfpq:
                image_searcher.train(img_embs)
            image_searcher.add_batch(img_embs, img_metas)
            image_searcher.save()
            print(f"âœ… Static image index built successfully. Samples: {len(img_embs)}, nlist: {nlist}, use_ivfpq: {use_ivfpq}")
        else:
            print("âš ï¸ No valid images processed")
else:
    print("âš ï¸ Image directory data/images/ not found")

print("ğŸ‰ Index building completed!")
print("ğŸ“ Generated files:")
print("  - data/faiss_text.bin (text index)")
print("  - data/faiss_text.pkl (text metadata)")
print("  - data/faiss_image.bin (image index)")
print("  - data/faiss_image.pkl (image metadata)") 