import os
from image_pipeline import clip_processor, clip_model, get_image_embedding
from faiss_pipeline import FaissMultiModalSearch
import torch

print("üöÄ Building indexes for AI Challenge HCM...")

# Build index cho text (s·ª≠ d·ª•ng CLIP thay v√¨ SimCSE ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n)
print("üìù Building text index with CLIP...")
texts = []
metas = []

# T·ª± ƒë·ªông scan t·∫•t c·∫£ text files trong data/text/
text_dir = "data/text"
if os.path.exists(text_dir):
    text_files = [f for f in os.listdir(text_dir) if f.lower().endswith('.txt')]
    
    if not text_files:
        print("‚ö†Ô∏è No text files found in data/text/")
    else:
        print(f"üìÅ Found {len(text_files)} text files: {text_files}")
        
        for fname in text_files:
            fpath = os.path.join(text_dir, fname)
            print(f"üìñ Processing file: {fname}")
            
            with open(fpath, encoding="utf-8") as f:
                for i, line in enumerate(f):
                    text = line.strip()
                    if text:
                        texts.append(text)
                        metas.append({"file": fname, "line": i+1, "text": text})
else:
    print("‚ö†Ô∏è Text directory data/text/ not found")

# X·ª≠ l√Ω text v·ªõi CLIP (thay v√¨ SimCSE)
if texts:
    print(f"üìä Processing {len(texts)} text entries with CLIP...")
    embs = []
    for text in texts:
        # T·∫°o CLIP text embedding v·ªõi truncation
        inputs = clip_processor(text=[text], return_tensors="pt", padding=True, truncation=True, max_length=77)
        with torch.no_grad():
            emb = clip_model.get_text_features(**inputs)
        embs.append(emb[0].cpu().numpy())
    
    # S·ª≠ d·ª•ng FlatL2 cho d·ªØ li·ªáu nh·ªè, IVF+PQ cho d·ªØ li·ªáu l·ªõn
    use_ivfpq = len(embs) >= 256  # Ch·ªâ d√πng IVF+PQ khi c√≥ >= 256 samples
    nlist = min(16, len(embs) // 2) if len(embs) > 1 else 1
    
    # CLIP c√≥ dimension 512
    text_searcher = FaissMultiModalSearch(dim=512, index_path="data/faiss_text.bin", meta_path="data/faiss_text.pkl", nlist=nlist, use_ivfpq=use_ivfpq, use_cosine=True)
    if use_ivfpq:
        text_searcher.train(embs)
    text_searcher.add_batch(embs, metas)
    text_searcher.save()
    print(f"‚úÖ Text index built successfully with CLIP + Cosine. Samples: {len(embs)}, nlist: {nlist}, use_ivfpq: {use_ivfpq}")
else:
    print("‚ö†Ô∏è No text files found in data/text/")

# Build index cho video (nhi·ªÅu frames)
print("üñºÔ∏è Building image index from video frames...")
try:
    import cv2
    vid_dir = "data/vid"
    vid_embs = []
    vid_metas = []
    
    if os.path.exists(vid_dir):
        video_files = [f for f in os.listdir(vid_dir) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]
        
        if not video_files:
            print("‚ö†Ô∏è No video files found in data/vid/")
        else:
            for fname in video_files:
                vid_path = os.path.join(vid_dir, fname)
                vidcap = cv2.VideoCapture(vid_path)
                
                if not vidcap.isOpened():
                    print(f"‚ùå Cannot open video: {fname}")
                    continue
                
                # L·∫•y th√¥ng tin video
                total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = vidcap.get(cv2.CAP_PROP_FPS)
                duration = total_frames / fps if fps > 0 else 0
                
                print(f"üìπ Processing video: {fname} ({total_frames} frames, {duration:.1f}s)")
                
                # Extract nhi·ªÅu frames (m·ªói 2 gi√¢y 1 frame)
                frame_interval = max(1, int(fps * 2))  # 1 frame m·ªói 2 gi√¢y
                frame_count = 0
                
                for frame_idx in range(0, total_frames, frame_interval):
                    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                    success, image = vidcap.read()
                    
                    if success:
                        # L∆∞u frame t·∫°m th·ªùi
                        frame_path = os.path.join(vid_dir, f"{fname}_frame_{frame_count}.jpg")
                        cv2.imwrite(frame_path, image)
                        
                        # T·∫°o embedding cho frame
                        emb = get_image_embedding(frame_path)
                        vid_embs.append(emb)
                        
                        # Metadata cho frame
                        frame_time = frame_idx / fps if fps > 0 else 0
                        vid_metas.append({
                            "file": fname,
                            "description": f"Frame {frame_count} t·∫°i {frame_time:.1f}s c·ªßa video {fname}",
                            "frame_number": frame_count,
                            "frame_time": frame_time
                        })
                        
                        frame_count += 1
                        
                        # X√≥a file t·∫°m
                        os.remove(frame_path)
                
                vidcap.release()
                print(f"‚úÖ Extracted {frame_count} frames from {fname}")
            
            if vid_embs:
                # S·ª≠ d·ª•ng FlatIP cho video frames v·ªõi cosine similarity
                video_searcher = FaissMultiModalSearch(dim=512, index_path="data/faiss_image.bin", meta_path="data/faiss_image.pkl", use_ivfpq=False, use_cosine=True)
                video_searcher.add_batch(vid_embs, vid_metas)
                video_searcher.save()
                print(f"‚úÖ Video frames index built successfully with Cosine. Samples: {len(vid_embs)}")
            else:
                print("‚ö†Ô∏è No video frames extracted")
    else:
        print("‚ö†Ô∏è Video directory data/vid/ not found")
        
except ImportError:
    print("‚ö†Ô∏è OpenCV not available, skipping video processing")
except Exception as e:
    print(f"‚ùå Error processing videos: {e}")

# Build index cho static images
print("üñºÔ∏è Building static image index...")
try:
    img_dir = "data/images"
    img_embs = []
    img_metas = []
    
    if os.path.exists(img_dir):
        image_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not image_files:
            print("‚ö†Ô∏è No image files found in data/images/")
        else:
            print(f"üìÅ Found {len(image_files)} image files: {image_files}")
            
            for fname in image_files:
                img_path = os.path.join(img_dir, fname)
                print(f"üñºÔ∏è Processing image: {fname}")
                
                # T·∫°o embedding cho image
                emb = get_image_embedding(img_path)
                img_embs.append(emb)
                
                # Metadata cho image
                img_metas.append({
                    "file": fname,
                    "description": f"·∫¢nh {fname}",
                    "type": "static_image"
                })
            
            if img_embs:
                # S·ª≠ d·ª•ng FlatIP cho static images v·ªõi cosine similarity
                static_image_searcher = FaissMultiModalSearch(dim=512, index_path="data/faiss_image_img.bin", meta_path="data/faiss_image_img.pkl", use_ivfpq=False, use_cosine=True)
                static_image_searcher.add_batch(img_embs, img_metas)
                static_image_searcher.save()
                print(f"‚úÖ Static images index built successfully with Cosine. Samples: {len(img_embs)}")
            else:
                print("‚ö†Ô∏è No static images processed")
    else:
        print("‚ö†Ô∏è Images directory data/images/ not found")
        
except Exception as e:
    print(f"‚ùå Error processing static images: {e}")

print("üéâ All indexes built successfully!") 